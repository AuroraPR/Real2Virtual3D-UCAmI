{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4ce3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "names ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "imgsz 640\n",
      "GO\n",
      "1/1: rtsp://Adetem:AuroraJavi@192.168.15.146:554/stream2...  success (640x360 at 15.00 FPS).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "BG_COLOR = (192, 192, 192)\n",
    "\n",
    "\n",
    "path =\"./data-avatar/\"\n",
    "#path_raw =path+\"raw/\"\n",
    "path_img =path+\"img/\"\n",
    "path_3d =path+\"3D/\"\n",
    "\n",
    "\n",
    "time2write=1\n",
    "\n",
    "\n",
    "#files = glob.glob(path_fuzzy+\"*\")\n",
    "#for f in files:\n",
    "#    os.remove(f)\n",
    "\n",
    "#files = glob.glob(path_raw+\"*\")\n",
    "#for f in files:\n",
    "#    os.remove(f)\n",
    "\n",
    "\n",
    "pose=mp_pose.Pose(static_image_mode=True,model_complexity=2,enable_segmentation=True,min_detection_confidence=0.5)\n",
    "\n",
    "device=select_device('')\n",
    "model = attempt_load('yolov7.pt', map_location=device)  \n",
    "\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "imgsz=640\n",
    "stride = int(model.stride.max())  # model stride\n",
    "imgsz = check_img_size(imgsz, s=stride) \n",
    "old_img_w = old_img_h = imgsz\n",
    "old_img_b = 1\n",
    "print(\"names\",names)\n",
    "print(\"imgsz\",imgsz)\n",
    "    \n",
    "\n",
    "print(\"GO\")\n",
    "dataset = LoadStreams(\"rtsp://Adetem:AuroraJavi@192.168.15.146:554/stream2\", img_size=imgsz, stride=stride)\n",
    "\n",
    "#count=0\n",
    "#count=0\n",
    "\n",
    "\n",
    "lastts = time.time()\n",
    "    \n",
    "for path, img, im0s, vid_cap in dataset:\n",
    "    print(\"\")\n",
    "    ts = time.time()\n",
    "    \n",
    "    frame = im0s[0]\n",
    "    \n",
    "    write=False\n",
    "    if(ts-lastts>time2write):\n",
    "        print(\"Time:\",ts,lastts)\n",
    "        lastts=ts\n",
    "        write=True\n",
    "        \n",
    "    orig=np.array(frame, copy=True) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if(write):\n",
    "    #    print('Original Dimensions : ',frame.shape)\n",
    "    #    cv2.imwrite(path_raw+str(ts)+\".jpg\", frame)\n",
    "    \n",
    "    width0=frame.shape[1]\n",
    "    height0=frame.shape[0]\n",
    "    \n",
    "    \n",
    "    if(write):\n",
    "        cv2.imwrite(path_img+str(ts)+\".png\", frame, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "    \n",
    "        img = torch.from_numpy(frame).to(device)\n",
    "        print(img)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "    \n",
    "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
    "                old_img_b = img.shape[0]\n",
    "                old_img_h = img.shape[2]\n",
    "                old_img_w = img.shape[3]\n",
    "                for i in range(3):\n",
    "                    model(img, augment=False)[0]\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
    "            pred = model(img, augment=False)[0]\n",
    "        t2 = time_synchronized()\n",
    "            \n",
    "        pred = model(img, augment=False)[0]\n",
    "        print(pred)\n",
    "        \n",
    "        #results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        #ok_land=results.pose_landmarks\n",
    "        ok_land=False\n",
    "        if ok_land:\n",
    "            print(\n",
    "                f'Nose coordinates: ('\n",
    "                f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * width0}, '\n",
    "                f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * height0})'\n",
    "            )\n",
    "            annotated_image = frame.copy()\n",
    "            condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "            bg_image = np.zeros(frame.shape, dtype=np.uint8)\n",
    "            bg_image[:] = BG_COLOR\n",
    "            annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            cv2.imwrite(str(os.path.join(path_3d, str(ts)+\".png\")), annotated_image)\n",
    "            frame=annotated_image\n",
    "            # Plot pose world landmarks.\n",
    "            mp_drawing.plot_landmarks(\n",
    "                results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            print(\"results.pose_world_landmarks:\",results.pose_world_landmarks)\n",
    "\n",
    "        \n",
    "        hor = np.concatenate((orig, frame), axis=1)\n",
    "        cv2.imshow('webCam',hor)\n",
    "    \n",
    "    keyCode = cv2.waitKey(1)\n",
    "    if (keyCode == ord('s')):\n",
    "            break\n",
    "\n",
    "\n",
    "    if cv2.getWindowProperty('webCam', cv2.WND_PROP_VISIBLE) <1:\n",
    "        break\n",
    "        \n",
    "    #count=count+1\n",
    "    #if(count > 100):\n",
    "    #    break\n",
    "        \n",
    "    #time.sleep(3)        \n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e81d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
